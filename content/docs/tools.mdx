---
title: Tools
description: Give agents the ability to call functions
---

Tools let agents call your TypeScript functions. Each tool has a name, description, Zod parameter schema, and an execute function.

<Callout type="info" title="What Stratus handles for you">
Without an SDK, function calling with Azure OpenAI requires you to manually manage the message array, parse JSON arguments, dispatch to functions by name, and make a second API call with the results. Stratus eliminates all of that:

- **Automatic tool loop** — `run()` handles the full model → tool → model cycle, including multiple rounds and parallel calls
- **Zod validation** — Parameters are parsed and type-checked before your function runs. No `JSON.parse()` or `.get()` calls
- **Typed execute** — Your function receives typed params, not raw JSON strings
- **No dispatch table** — No `if name === "x" else if name === "y"`. Stratus routes to the right tool automatically
- **Retries and error handling** — 429 backoff, content filter errors, and tool errors are handled automatically
</Callout>

## Defining a Tool

```ts title="tools.ts"
import { tool } from "stratus/core";
import { z } from "zod";

const getWeather = tool({
  name: "get_weather",
  description: "Get the current weather for a city",
  parameters: z.object({
    city: z.string().describe("City name"),
    unit: z.enum(["celsius", "fahrenheit"]).optional(),
  }),
  execute: async (_ctx, { city, unit }) => {
    const temp = await fetchWeather(city, unit);
    return `${temp}° in ${city}`;
  },
});
```

## Tool Anatomy

| Property | Type | Description |
| --- | --- | --- |
| `name` | `string` | Unique tool name sent to the model |
| `description` | `string` | What the tool does (helps the model decide when to use it) |
| `parameters` | `z.ZodType` | Zod schema for the parameters |
| `execute` | `(context, params, options?) => string` | Function that runs when the model calls the tool |

The `execute` function receives up to three arguments:
1. **`context`** — The context object passed via `run()` options or session config
2. **`params`** — Parsed and validated parameters matching the Zod schema
3. **`options`** — Optional `ToolExecuteOptions` with an `AbortSignal` for cancellation

## Using Context

Tools can access shared context for things like database connections, API clients, or user info:

```ts title="context-tool.ts"
interface AppContext {
  userId: string;
  db: Database;
}

const lookupOrder = tool({
  name: "lookup_order",
  description: "Look up an order by ID",
  parameters: z.object({ orderId: z.string() }),
  execute: async (ctx: AppContext, { orderId }) => {
    const order = await ctx.db.orders.find(orderId, ctx.userId);
    return JSON.stringify(order);
  },
});

const agent = new Agent<AppContext>({
  name: "support",
  model,
  tools: [lookupOrder],
});

await run(agent, "Where is my order #123?", {
  context: { userId: "user_abc", db: myDb },
});
```

## Passing Tools to Agents

```ts
const agent = new Agent({
  name: "assistant",
  model,
  tools: [getWeather, lookupOrder, searchDocs],
});
```

## Passing Tools to Sessions

```ts
const session = createSession({
  model,
  tools: [getWeather, lookupOrder],
});
```

## Tool Call Flow

<Steps>
<Step>

### Model returns a tool call

The model responds with a tool call containing a name and JSON arguments.

</Step>
<Step>

### Arguments are parsed

Stratus parses the arguments JSON and validates them against the Zod schema.

</Step>
<Step>

### Execute function runs

The `execute` function runs with the parsed parameters and context.

</Step>
<Step>

### Result sent back to model

The result string is sent back to the model as a tool message.

</Step>
<Step>

### Model generates final response

The model generates a final response (or calls more tools). This loop continues until the model responds without tool calls, or `toolUseBehavior` causes an early stop.

</Step>
</Steps>

## Abort Signal

When a run is started with an `AbortSignal`, it's passed to each tool's `execute` function via the `options` parameter. Use it to cancel long-running operations:

```ts title="abort-aware-tool.ts"
const searchTool = tool({
  name: "search",
  description: "Search documents",
  parameters: z.object({ query: z.string() }),
  execute: async (_ctx, { query }, options) => { // [!code highlight]
    const res = await fetch(`/api/search?q=${query}`, {
      signal: options?.signal, // [!code highlight]
    });
    return await res.text();
  },
});
```

See [Streaming — Abort Signal](/docs/streaming#abort-signal) for details on passing a signal.

## Error Handling

If a tool's `execute` function throws, the error message is sent back to the model as the tool result. This lets the model recover gracefully:

```ts
execute: async (_ctx, { query }) => {
  const results = await search(query);
  if (results.length === 0) {
    throw new Error("No results found. Try a different query.");
  }
  return JSON.stringify(results);
},
```

## Schema Conversion

<Callout>
Stratus converts Zod schemas to JSON Schema for the Azure API. The conversion adds `additionalProperties: false` to all objects for Azure strict mode compatibility.
</Callout>

Supported Zod types include objects, strings, numbers, booleans, arrays, enums, optionals, nullables, defaults, unions, and descriptions.

## Compared to Raw Azure OpenAI

To illustrate what Stratus handles, here's a weather + time lookup with two tools:

<Tabs items={["Stratus", "Without SDK"]}>
<Tab value="Stratus">

```ts title="stratus.ts"
import { AzureResponsesModel } from "stratus";
import { Agent, run, tool } from "stratus/core";
import { z } from "zod";

const model = new AzureResponsesModel({
  endpoint: process.env.AZURE_ENDPOINT!,
  apiKey: process.env.AZURE_API_KEY!,
  deployment: "gpt-5.2",
});

const getWeather = tool({
  name: "get_weather",
  description: "Get weather for a city",
  parameters: z.object({
    location: z.string().describe("City name"),
  }),
  execute: async (_ctx, { location }) => fetchWeather(location),
});

const getTime = tool({
  name: "get_time",
  description: "Get current time for a city",
  parameters: z.object({
    location: z.string().describe("City name"),
  }),
  execute: async (_ctx, { location }) => fetchTime(location),
});

const agent = new Agent({
  name: "assistant",
  model,
  tools: [getWeather, getTime],
});

// Parallel tool calls, multi-turn loop, retries — all automatic
const result = await run(
  agent,
  "Weather and time in San Francisco, Tokyo, and Paris?"
);
console.log(result.output);
```

</Tab>
<Tab value="Without SDK">

```python title="manual.py"
import json
from openai import OpenAI

client = OpenAI(
    base_url="https://YOUR-RESOURCE.openai.azure.com/openai/v1/",
    api_key="YOUR_KEY",
)

# Step 1: Define tools as raw JSON
tools = [
    {"type": "function", "function": {
        "name": "get_weather", "description": "Get weather",
        "parameters": {"type": "object", "properties": {
            "location": {"type": "string"}
        }, "required": ["location"]}
    }},
    {"type": "function", "function": {
        "name": "get_time", "description": "Get time",
        "parameters": {"type": "object", "properties": {
            "location": {"type": "string"}
        }, "required": ["location"]}
    }},
]

# Step 2: First API call
messages = [{"role": "user", "content": "Weather and time in SF, Tokyo, Paris?"}]
response = client.chat.completions.create(
    model="gpt-5.2", messages=messages, tools=tools
)

# Step 3: Manually parse response and append to messages
msg = response.choices[0].message
messages.append(msg)

# Step 4: Manually dispatch each tool call
if msg.tool_calls:
    for tc in msg.tool_calls:
        args = json.loads(tc.function.arguments)  # hope it's valid JSON
        if tc.function.name == "get_weather":
            result = fetch_weather(args.get("location"))
        elif tc.function.name == "get_time":
            result = fetch_time(args.get("location"))
        else:
            result = json.dumps({"error": "Unknown"})
        messages.append({
            "tool_call_id": tc.id, "role": "tool",
            "name": tc.function.name, "content": result,
        })

# Step 5: Second API call for the final answer
final = client.chat.completions.create(model="gpt-5.2", messages=messages)
print(final.choices[0].message.content)

# No streaming, no retries, no validation, no error handling,
# no multi-round tool loops, no abort support.
```

</Tab>
</Tabs>

The Stratus version handles parallel tool calls, multi-round tool loops, argument validation, error recovery, 429 retries, streaming, and abort signals — none of which exist in the manual approach.
