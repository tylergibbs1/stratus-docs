---
title: Azure OpenAI
description: Configure Azure Chat Completions and Responses API models
---

Stratus includes two built-in Azure OpenAI model implementations. Both implement the `Model` interface and work with all Stratus APIs (agents, tools, sessions, streaming, etc.).

| Model | API | Best for |
| --- | --- | --- |
| `AzureChatCompletionsModel` | Chat Completions | General use, widest compatibility |
| `AzureResponsesModel` | Responses API | Newer API format, same capabilities |

## AzureChatCompletionsModel

Uses the Azure Chat Completions API (`/openai/deployments/{deployment}/chat/completions`).

```ts title="chat-completions.ts"
import { AzureChatCompletionsModel } from "stratus/azure";

const model = new AzureChatCompletionsModel({
  endpoint: "https://your-resource.openai.azure.com",
  apiKey: "your-api-key",
  deployment: "gpt-5.2",
  apiVersion: "2025-03-01-preview", // optional, this is the default
});
```

### Config Options

| Property | Type | Description |
| --- | --- | --- |
| `endpoint` | `string` | **Required.** Azure OpenAI endpoint URL |
| `apiKey` | `string` | **Required.** API key for authentication |
| `deployment` | `string` | **Required.** Model deployment name |
| `apiVersion` | `string` | API version (default: `"2025-03-01-preview"`) |

## AzureResponsesModel

Uses the Azure Responses API (`/openai/responses`). The deployment name is sent as `model` in the request body rather than in the URL path.

```ts title="responses.ts"
import { AzureResponsesModel } from "stratus/azure";

const model = new AzureResponsesModel({
  endpoint: "https://your-resource.openai.azure.com",
  apiKey: "your-api-key",
  deployment: "gpt-5.2",
  apiVersion: "2025-04-01-preview", // optional, this is the default
});
```

### Config Options

| Property | Type | Description |
| --- | --- | --- |
| `endpoint` | `string` | **Required.** Azure OpenAI endpoint URL |
| `apiKey` | `string` | **Required.** API key for authentication |
| `deployment` | `string` | **Required.** Sent as `model` in request body |
| `apiVersion` | `string` | API version (default: `"2025-04-01-preview"`) |

<Callout type="info">
Both models are interchangeable. Swap one for the other without changing any agent, tool, or session code.
</Callout>

## Usage

Both models implement the `Model` interface and work identically with all Stratus APIs:

```ts
// With run()
const result = await run(agent, "Hello", { model });

// With createSession()
const session = createSession({ model, instructions: "..." });

// With prompt()
const result = await prompt("Hello", { model });
```

## Model Interface

Any model provider can be used with Stratus by implementing the `Model` interface:

```ts title="model-interface.ts"
interface Model {
  getResponse(request: ModelRequest, options?: ModelRequestOptions): Promise<ModelResponse>;
  getStreamedResponse(request: ModelRequest, options?: ModelRequestOptions): AsyncIterable<StreamEvent>;
}

interface ModelRequestOptions {
  signal?: AbortSignal; // [!code highlight]
}
```

<Callout type="info">
The `options` parameter is optional and backward compatible. When provided, `signal` is used for request cancellation.
</Callout>

### ModelRequest

```ts title="types.ts"
interface ModelRequest {
  messages: ChatMessage[];
  tools?: ToolDefinition[];
  modelSettings?: ModelSettings;
  responseFormat?: ResponseFormat;
}
```

### ModelResponse

```ts title="types.ts"
interface ModelResponse {
  content: string | null;
  toolCalls: ToolCall[];
  usage?: UsageInfo;
  finishReason?: string; // [!code highlight]
}
```

### UsageInfo

```ts title="types.ts"
interface UsageInfo {
  promptTokens: number;
  completionTokens: number;
  totalTokens: number;
  cacheReadTokens?: number; // [!code highlight]
  cacheCreationTokens?: number; // [!code highlight]
}
```

<Callout>
Cache token fields are populated when the Azure API returns `prompt_tokens_details.cached_tokens`. They're `undefined` when caching is not active.
</Callout>

## Authentication

Both implementations use `api-key` header authentication. The API key is sent as a header with every request.

## Streaming

Both models use Server-Sent Events (SSE) with a shared zero-dependency parser. Events are yielded as `StreamEvent` objects as they arrive from the Azure API.

## Error Handling

Both models throw the same errors for failure modes:

- **`ModelError`** - General API errors (4xx/5xx responses)
- **`ContentFilterError`** - Azure content filter blocked the request or response

```ts title="error-handling.ts"
import { ModelError, ContentFilterError } from "stratus/core";

try {
  const result = await run(agent, input);
} catch (error) {
  if (error instanceof ContentFilterError) {
    // Handle content filter
  } else if (error instanceof ModelError) {
    console.error(`API error ${error.status}: ${error.message}`);
  }
}
```

Both models also retry on `429` (rate limit) responses with exponential backoff, respecting the `Retry-After` header when present.
