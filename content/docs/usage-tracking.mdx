---
title: Usage & Token Tracking
description: Monitor token consumption across agent runs
---

Every agent run tracks token usage. Access `RunResult.usage` to monitor costs, enforce limits, and debug consumption. Usage is aggregated across all model calls in a run, including tool loops.

## Accessing Usage

After a `run()` completes, the result includes accumulated usage across all model calls:

```ts title="usage.ts"
import { Agent, run } from "stratus/core";

const agent = new Agent({ name: "assistant", model });
const result = await run(agent, "Explain TypeScript generics");

console.log(result.usage.promptTokens);      // Total prompt tokens
console.log(result.usage.completionTokens);  // Total completion tokens
console.log(result.usage.totalTokens);       // Sum of prompt + completion
console.log(result.usage.cacheReadTokens);   // Tokens read from cache (if available)
console.log(result.usage.cacheCreationTokens); // Tokens written to cache (if available)
```

## UsageInfo Reference

| Property | Type | Description |
| --- | --- | --- |
| `promptTokens` | `number` | Total tokens in the prompt (system + messages + tool definitions) |
| `completionTokens` | `number` | Total tokens generated by the model |
| `totalTokens` | `number` | Sum of `promptTokens` and `completionTokens` |
| `cacheReadTokens` | `number?` | Tokens served from Azure's prompt cache |
| `cacheCreationTokens` | `number?` | Tokens written to the prompt cache |

<Callout type="info">
Cache token fields are only present when Azure returns prompt caching details. When unavailable, they are `undefined` rather than `0`.
</Callout>

## Usage Across Tool Loops

<Callout type="info">
When a run involves multiple model calls (tool calls followed by a final response), usage is the sum across all calls.
</Callout>

Each model call in the run loop adds its tokens to the running total. A run that calls two tools makes at least two model calls - one that produces the tool calls, and one that generates the final response:

```ts title="tool-usage.ts"
import { Agent, run, tool } from "stratus/core";
import { z } from "zod";

const getWeather = tool({
  name: "get_weather",
  description: "Get weather for a city",
  parameters: z.object({ city: z.string() }),
  execute: async (_ctx, { city }) => `72F in ${city}`,
});

const agent = new Agent({
  name: "weather",
  model,
  tools: [getWeather],
});

const result = await run(agent, "Weather in NYC and London?");

// Usage includes BOTH model calls:
//   1. Model call that produced the tool calls
//   2. Model call that generated the final response
console.log(result.usage.promptTokens);     // ~300 (sum of both calls)
console.log(result.usage.completionTokens); // ~80  (sum of both calls)
console.log(result.usage.totalTokens);      // ~380
```

## Usage in Streaming

When streaming, usage arrives in the `done` event's `response.usage` field. This is the usage for a single model call. The aggregated total is available on the final `RunResult`:

```ts title="stream-usage.ts"
import { Agent, stream } from "stratus/core";

const agent = new Agent({ name: "writer", model });
const { stream: s, result } = stream(agent, "Write a haiku");

for await (const event of s) {
  if (event.type === "content_delta") {
    process.stdout.write(event.content);
  }
  if (event.type === "done") {
    // Per-call usage from this model response
    console.log("This call:", event.response.usage?.totalTokens); // [!code highlight]
  }
}

// Aggregated usage across the entire run
const finalResult = await result;
console.log("Total:", finalResult.usage.totalTokens); // [!code highlight]
```

## Tracking Costs

Build a simple cost calculator using the usage fields. Token prices depend on your Azure deployment and model:

```ts title="costs.ts"
import type { UsageInfo } from "stratus/core";

interface TokenPricing {
  promptPer1k: number;
  completionPer1k: number;
  cachedPromptPer1k?: number;
}

function estimateCost(usage: UsageInfo, pricing: TokenPricing): number {
  const promptCost = (usage.promptTokens / 1000) * pricing.promptPer1k;
  const completionCost = (usage.completionTokens / 1000) * pricing.completionPer1k;

  // Subtract cached tokens if a lower cached rate applies
  let cacheDiscount = 0;
  if (usage.cacheReadTokens && pricing.cachedPromptPer1k !== undefined) {
    const savings = pricing.promptPer1k - pricing.cachedPromptPer1k;
    cacheDiscount = (usage.cacheReadTokens / 1000) * savings;
  }

  return promptCost + completionCost - cacheDiscount;
}

// Example: gpt-5.2 pricing (hypothetical)
const pricing: TokenPricing = {
  promptPer1k: 0.005,
  completionPer1k: 0.015,
  cachedPromptPer1k: 0.0025,
};

const result = await run(agent, "Summarize this document");
const cost = estimateCost(result.usage, pricing);
console.log(`Estimated cost: $${cost.toFixed(4)}`);
```

## Usage with Sessions

When using sessions, each `stream()` call produces its own `RunResult` with usage for that turn:

```ts title="session-usage.ts"
import { createSession } from "stratus/core";

const session = createSession({ model, instructions: "You are a helpful assistant." });

session.send("What is TypeScript?");
for await (const event of session.stream()) {
  if (event.type === "content_delta") process.stdout.write(event.content);
}

const turn1 = await session.result;
console.log("Turn 1 tokens:", turn1.usage.totalTokens);

session.send("How do generics work?");
for await (const event of session.stream()) {
  if (event.type === "content_delta") process.stdout.write(event.content);
}

const turn2 = await session.result;
console.log("Turn 2 tokens:", turn2.usage.totalTokens); // [!code highlight]

// Aggregate across turns manually
const totalTokens = turn1.usage.totalTokens + turn2.usage.totalTokens;
console.log("Session total:", totalTokens);
```

<Callout>
Each `session.result` contains usage for that turn only. To track cumulative session usage, sum across turns yourself.
</Callout>

## Usage with Tracing

Combine `withTrace()` with usage tracking for full observability. Model call spans automatically include usage in their metadata:

```ts title="traced-usage.ts"
import { withTrace, run, Agent } from "stratus/core";

const agent = new Agent({ name: "assistant", model, tools: [getWeather] });

const { result, trace } = await withTrace("weather_request", async () => {
  return run(agent, "What's the weather in Tokyo?");
});

// Run-level usage
console.log("Total tokens:", result.usage.totalTokens);

// Per-span usage from trace metadata
for (const span of trace.spans) {
  if (span.type === "model_call" && span.metadata?.usage) {
    console.log(`${span.name}: ${JSON.stringify(span.metadata.usage)}`); // [!code highlight]
  }
}
```

The trace gives you per-call breakdowns while `result.usage` gives you the aggregate. Together they show exactly where tokens were spent.

## Next Steps

- [Streaming](/docs/streaming) - Stream events include per-call usage in the `done` event
- [Tracing](/docs/tracing) - Inspect per-span usage metadata for detailed breakdowns
- [Sessions](/docs/sessions) - Track usage across multi-turn conversations
- [Tools](/docs/tools) - Understand how tool loops affect token consumption
